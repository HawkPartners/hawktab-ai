Jason Anderson  0:00  
Um, I think part of my, you know, broader question would be like, you know, it does this actually seem like a kind of a thing that, you know, takes time currently, and is actually like a pain point, or is it sort of something that, like, the industry sort of kind of figured out how to do pretty easily. And you know, this might save some time, but it's nothing too substantial,

Bob Hettel [Antares]  0:29  
I think, like a lot of things, the devil's in the details, right? So, you know, at a very, very high level, decipher gives you cross tabs, right? And those you know outside of just choosing what you want to include or exclude from the cross tab are set up in a matter of a couple minutes, having said that it doesn't do certain types of things at all, if not poorly, right? So, like a summary table it doesn't really do a good job of. And there's other tables that, again, it's not very good at, where traditional a traditional table works great. So kind of the same idea here, like thinking through some of the types of tables that are needed. You know, does the platform really accommodate those types where you know that compared to a traditional tab program would seemingly be quicker, even though the TAP programs these days are a lot better, if you will, they're not automatic. You still have to manipulate and do things. So it takes someone you know, say, a day to create tables or more, right? Checking, it's kind of another thing, right?

Jason Anderson  1:49  
Yeah, it's definitely very interesting. Yeah. I think the interesting thing is this the current system, you know, you're using kind of AI to do different aspects of the tab, you know, process, but you're using kind of deterministic code, you know, for that reliability piece. So it's not really having in terms of the background, it's not like I have, you know, AI agents, kind of running around and, you know, doing things kind of free will or freely, you're kind of embedding AI, right, where a human being, sort of intelligence, would be useful, and I think in this moment, is kind of what you're describing, where you know, when you get you know, there's a section in the workflow Where you know, we create tables for every variable, right? So that's like the first pass, and the second pass is, you know, if you are a consultant, right? If you were to think from that, how else would you want to see this variable kind of shown, right? And that's kind of where you get the top two box summary table. That's where you get, you know, certain combined ranking tables. That's where you get all those other sorts of tables that, as you're saying, is probably more difficult for a you know, program to do deterministically, because it is kind of like, you know, it's very variable. So I think that's definitely a piece that the system definitely kind of benefits from. I

Bob Hettel [Antares]  3:52  
You may or may not have, to your point, predetermined code to deal with. Like, I'm thinking of like, we run into stuff where you've got to, like, say, stack data, right? And you're running a stacked data banner. Like, I don't know if that's something you can accommodate or not, but that's usually a little unique. I'll say,

Jason Anderson  4:13  
Yeah, haven't tested a stacked data banner. Would have to kind of get an example, and get more of a sense of, kind of what that looks like, but definitely don't have any doubts in terms of whether or not this can handle that. Like a key piece here is, you know, we're using kind of our in the background, right? We're using basically just our script, which is, you know, which gives us a lot of flexibility. And just as AI is really good at writing code, it could easily write, or at least write the pieces of our script that's necessary to cut the data in a certain way. And then you could kind of deterministically, kind of put all those things together, right? Would love to, you know, get. An example of kind of a stacked banner, so I can maybe see how to make sure that can be incorporated. I've tried to keep it very general, so I'm not like hard coding certain rules, or, like, you know, if you see HCP, turn it into XYZ. I think I'm trying to give it broad patterns. And then the next steps for me, really is going through more of the files that you shared in testing, you know, how it, you know, matches or works on all of those, and then keep on, you know, making small little tweaks. But I would imagine, luckily, the one I use, I find, or the first project that I tested was one of the demand studies for lefeo, and it had a lot of weird tables, so it actually was a good test to see like for a more I want to say that that survey is that complex, but it has a lot of what do you call it, like columns and rows and just a lot of weird variable structure that kind of the model was able to sort of decipher. But, yeah, one thing that I didn't show in the video was this part because I had it turned off. So I think it would be good to kind of share this piece real quick, if you could see my screen. So I had the pipeline running just in the background, just because it takes around actually drop the time from like that hour to around 35 minutes. And there's even more time savings that could be, got, gotten. But So this section here is for that human in the loop section where it gives the user the opportunity to confirm kind of the variable expression that the AI is going to be using for the, you know, the cut of the data. Okay, it pops up once the AI has a sense of when it's a bit not as confident as other tables or other values. And I think this is an important piece of the equation, because sometimes there are variables that can go either way, and it just gives the user that ability to confirm. So in the first case, the banner says this. The AI is suggesting kind of an R expression here, and it's giving you the alternative to choose some other alternatives based on what it saw in the data. And this screen could definitely be optimized, but it's kind of a mock draft of it, and it kind of breaks down, kind of why it made why it's uncertain. In this case, it's correct. That's kind of what I wanted. So that's fine. It kind of defaults to accept there. And then for the tiers, this is an interesting part. When you're looking at the list, there's many different tier variables, right? So it ends up giving you a sense of, here's some other tiers that you could be choosing, right, right? It actually is correct here as well.

Bob Hettel [Antares]  8:06  
Now in that particular instance, for example, is that, just because, when you wrote the banner plan, really use a variable label for that and just sort of set generically tier

Jason Anderson  8:17  
exactly, I kind of try to have it work with what partners would actually do, right? So, or typically, obviously, if you're more specific, then it'll be work more reliably. But in some cases, there's even a cut that says, you know, kind of Joe to find the midpoint or something, right? And it kind of will take that and say, Okay, let me just do the median, higher, lower. So those are sort of the situations in which kind of we have this human in the loop section that can, what do you call it? Kind of give you that opportunity to validate how it's going to cut. And there's a lot of different, you know, adjustments that this system could make. But, yeah, that's effectively what I also wanted to show, is just that human in the loop piece, and then, yeah, things of that nature. So any other kind of questions or thoughts

Bob Hettel [Antares]  9:23  
Yeah, got a couple. But Raina, anything on your mind?

Raina Friedman [Antares]  9:30  
No, I guess it would be interesting. Are we able to see like the final output can Is that something you could share so we could kind of see how it handles the stat testing and yeah, Banner

Jason Anderson  9:45  
setup, yeah, I could go to the last one I did here, and then I also shared this with Bob, but I'll move this over. So the stat testing section part was. See where is it? Let's go here. Okay, so here's kind of how it looks. Actually took inspiration from the tabs that you all kind of provide us. There's kind of some auto sorting of some of the question a lot of these question texts I am working on, trying to get them to be a bit more, you know, specific,

Raina Friedman [Antares]  10:21  
but we're not able to see the file. Oh, okay, let me share,

Jason Anderson  10:27  
let me share my actual screen here. Okay, do you see? No, yes. Okay, perfect. So, yeah, I took inspiration from you all, or the tabs that you all provide us. And there's still some kind of things that I would love to work on here, but for the most part, it's, you know, once again, very deterministic, right? It knows what tables is going to create. It's the tables are created kind of as separate tables, and then we kind of stitch it together and then how it handles stat testing. We, I kind of reached out to Joe to kind of see how he handles our stat testing ad hoc partners, and I just kind of applied, or ensure that that same logic was applied here. So yeah, this is pretty much the banner, and there's some more things that I can do here that I'm I'm thinking of

Bob Hettel [Antares]  11:25  
one question I have, is it possible to add in an option to say I only want percents or frequencies?

Jason Anderson  11:32  
Or, yeah, totally, definitely, definitely possible. Definitely possible.

Bob Hettel [Antares]  11:39  
I know sometimes we get a request to run one or the other as a separate output.

Jason Anderson  11:45  
Yeah, yeah. I do see that we all we often get different types of tables or with a different sort of focus. So definitely can make sure that that's implemented. That's a very kind of easy addition, for sure.

Bob Hettel [Antares]  12:01  
So I have a question about sort of the inputs, right? So obviously it's taking an SPSS file on the map from the SPS file. So that's pretty standard in terms of the banner plan that you're uploading and or the questionnaire. Is it? Obviously, every questionnaire is a bit different. But is it able to, I'm assuming it's able to digest the questionnaire regardless of format. Or is there any kind of like your questionnaire needs to sort of look like this in terms of how it's set up or labeled or whatever? Same thing with the tap plan. Do you kind of have to have a standard format for the tab plan, or can you kind of take whatever it's thrown at it?

Jason Anderson  12:44  
Yeah, so definitely not super rigid in that way. On the survey side of things, we currently, or I'm only currently, uploading documents, but, or, like a Word doc, but I can imagine PDFs work, and I think that's all you would use for a survey, potentially. I mean, I'm not really sure, but at least for my current thinking, Word doc and PDFs can be supported. And what the model does is the actual structure of the survey does not really matter. I don't really tell it how the survey comes in, and initially it just takes ingest whatever is given to it, and kind of it knows that it's a survey, and from there, it's able to understand what do you call it, kind of the structure of the survey. So if that answers that question, it doesn't need to be a specific way to show the survey in terms of kind of the structure or the file type, at least not from the file types that I would imagine would get uploaded, right? But yeah, I mean, yeah,

Bob Hettel [Antares]  13:48  
she's thinking like, you know, some people will label their questions like Q, s2 or whatever, right, right? Some people will just use s2 like, like. Numbering systems vary a lot. How people format, like a grid can change a lot. So it's just curious, like some people use letters, some people use numbers, just curious, like, if any of that really mattered, and sort of in terms of the Word doc itself,

Jason Anderson  14:15  
yeah, I wouldn't say it would, but I would have to test a Word document that has kind of those different, you know, patterns. As I said, part of what I'll be doing is testing all the surveys you gave us and then, or that, you know, the data we have, and kind of validating it against those obviously hot partners has its own version of surveys. So maybe that's a place where, you know, you all could potentially, you know, test it on some other stuff, and then you know that that could tell us whether or not it's as reliable. I do think it would be, because even those surveys that have different, you know, patterns, they still have patterns, right? And the AI is basically. Learning the pattern. It copies the data map, or it doesn't copy the data map, but it's able to reference the data map and the survey. And from there, I think, as a human would, it'll be able to determine what is related to what so that's answers that part. And then, in terms of the banner plan, currently, it's based on kind of a Word document as well. I can imagine a PDF works as well. And in that case, I wouldn't think that there is a specific format, right? It's kind of taught, or, you know, focused on, once again, patterns, right? What looks like a group, right? What looks like a cut? Cuts typically have a filter. You know, groups typically look like x or have us, you know, it's kind of told about the abstract nature of what a banner plan is. And basically, as long as you can look at it, whatever you're given in, you know, convert, you know, whatever, into kind of this JSON format that says, This is the group. These are the columns. These are the group. These are the columns. If you can do that, then you pretty much, you know, then it's pretty easy for the AI to handle that. I do know some people do Excel sheets, so I haven't tried that. Not really worried again. If that is the case, it's just a different maybe uploading, parsing upfront, but the output of that, I would imagine, would probably even be easier for the AI, because then we could just deterministically take that Excel sheet, parse it into the structure that we want, and we might not even need AI to even handle that.

Raina Friedman [Antares]  16:33  
So, yeah, yeah, and the example that you had given with regard to the the tiers and the human validation. So I'm wondering a lot of times, we'll just get a banner plan and it's just like words, like there's no spec provided at all. So based on what you had shown, the system will be able to try to locate the data point based on just the text and without a spec provided at all?

Jason Anderson  16:59  
Yeah, exactly. And it was interesting. Yeah, it was interesting is, you know, it made me think you don't even really need to give a banner plan, right? I mean, an AI could probably figure out what cuts you want, right, based on just the survey itself. And there is no, you know, maybe for a human it might be more time intensive to cut, you know, or like, over create banners, right? But this system might be able to create you banner, 1231, being the most key, cuts to, you know, being the less key, and then third being kind of like miscellaneous. And it could probably, like, infer based on best practices. Or even maybe there's a prompt that the user in their upload says, like, I want you to kind of focus on these groups, and they can probably find it for you. I haven't kind of built in that system yet, but that's definitely on the list of like, do you even need to give a banner in the first place?

Raina Friedman [Antares]  17:52  
Yeah, yeah. I was just thinking that would be a big time saver for the partners on your side. If they don't have to spec out a banner, they can just say, generally, like, I want to look at specialty tiers and whatever, and then it would just do it, and they wouldn't have to spend the time breaking out every single bucket. And then they could just validate it. Yes, that's what I wanted. No, that's not what I wanted. Right?

Jason Anderson  18:16  
Right? No, yeah, totally, totally, yeah. So, you know, still kind of working on, as I said, kind of the testing piece of this. But all these ideas are definitely helpful. Some of them were things that I was thinking about. Some of them are things that I will begin thinking about, just because I don't have so much visibility into how non Hawk partners, banners look like, right? Or non hot partners workflows look like so, you know, hearing that there's people who even send banners with no spec is pretty interesting. I definitely interview those people. I think, I think that's definitely good to know. Awesome.

Raina Friedman [Antares]  18:58  
Yeah. I mean, in my mind, as Bob mentioned earlier, one of the major, I think, components to figure out would be with regard to any stack data, because special tables in Table runs as a standard for Hawk, like whenever there's concepts or any loops whatsoever, even brand and company ratings were asked to stack the data and create a banner with the concepts or the brands or whatever as the banner points. So I'm wondering how it would handle that, like if it would know how to read a loop of data and say, okay, you know a for underscore one, underscore three, and then the next one, a four, underscore one, and it would know, if it's underscore one, that's Loop One. And I want to compare those same questions to the second loop, that kind of thing. And I'm so I'd be interested to see how that would work. And maybe it could be as easy as, whenever you have a loop, you have a identifier that says, like, loop starts here or something, and then that way, AI would be like, Oh, here's the loop. I'm going to make a special table right,

Jason Anderson  20:12  
right now. That's a good, good, good flag. I would definitely look into that. I'm starting to get a sense of what you meant by stacked So, yeah, I definitely think probably some prompt enhancements. Maybe there's a another layer that is able to kind of determine kind of if there is even a loop in the data map in general, and then it could, if not, then it kind of goes the standard route. If so, maybe there's a different pathway that's a bit kind of more what do you call it? Focused on that piece, or that prompted differently to make sure it catches that. But um yeah, that's definitely a good flag. Yeah, yep. In terms of another thing, I guess two things being, let's see. One thing I was questioning, Bob kind of touched on this in the email. But when you're thinking of, you know, these sorts of traditional cross tabs, right? Like, how is, do we think this is something that the industry is going to continue to do for the next couple years? Or do we see, like, things like display or and Q and, you know, Power BI kind of taking over, you know, is, are these traditional cross tabs kind of still widely used across the industry,

Bob Hettel [Antares]  21:42  
that's a good question. So I think it depends a lot on where you sit in the industry. If you're a traditional market research company, say, like the T and SS of the world, right? Or that type of company, I still think that for most people, their standard tables are what they expect. Part of that, though, goes back to how would you otherwise get like, tab like at the end of the day, I still see more clients than not wanting every single question in a PowerPoint deck, right? And so that generally comes from a set of tables as a general statement, right? For some companies. I mean, obviously you could put q into every user's hands, but that becomes very expensive to do. And so I think depending on the size of the company, it's going to vary a lot, like I can have two tab programmers in India doing my tables, or I can have, you know, every single person in the company doing tables, and again, I say doing tables that could be in queue or something else to generate that level of data that they're reporting, right? So I have seen a bigger shift over the last several years to tools like Q. Interestingly enough, I know a company that went from using offshore tab people to deliver Q data, so the offshore team would build, essentially the Q pack with all of the kind of tabs built into Q. They would deliver that to the project team. The project team could then access those tables in queue and, you know, export to PowerPoint or whatever they were going to do with that data. They then also had the ability, at that point to start working on any kind of special needs they would have without having to go back to the tab team because it's in queue. So sort of a hybrid approach. That same company moved away from that, probably for their detriment, but they now have all of their project teams actually generating any tables that they need in SPSS, which is far more difficult to do than Q, especially for people who don't know scripting. So but they're still, like most of their teams, are still generating regular tables, but now they're doing it in SPSS, which to me, is just more complicated. And honestly, because they're not tap people or technology people, it's a little bit more cumbersome. So but we have other clients who have moved completely away from doing tabs, and they're 100% using Q to run whatever they're doing, yeah, but whether they're creating a traditional full set of tables in queue. I couldn't tell you my my suspicion is that they're probably not, yeah, that they're kind of, but again, I think at the same time, they're probably looking at most of the data to kind of figure out what the story is, and then pulling the parts that they need. Yeah. I think the industry will never go away from full tables just because that's who and what we are, right? Maybe someday I don't see it. In the near term, I see what they're going to start using as displayer to other tools similar to that, where people can run things on the fly or even in large numbers, but they're not necessarily going to do what we used to do with it.

Raina Friedman [Antares]  25:26  
Yeah, and I think too, in addition to the audience using the data tools, like whether it's a consultant, like a consultancy versus like a full service market research company, for example. I think Additionally, a big driver is the types of research that are being done. Because I think at least in my mind, a lot of the physician research that we see, some of like the more complex B to B research that we see is really so customized, and it requires a lot of digging through data, as opposed to some things that are like more on the, I don't want to say easier side, but some of the consumer research And just some market landscape stuff, you know that's more amenable to being able to use tools and only run certain tables. You don't need a full like in depth necessary for those. I do think that the type of research is also things will change faster in certain areas of research than in others.

Jason Anderson  26:38  
Yeah, and if you I'll have time, I have two more questions. Would be, like five perfect. So one of them was, had to do with some tabs we got from Antares yesterday. And actually it was for spravato work. And it they came pretty quickly, as well as the max diff turf, or at least, you know, I feel like you guys created the cross tabs ahead of time, and then, like, once the data file kind of was finished, you probably ran them again. But just curious, like, when it comes to the process of creating tables and kind of these Max diff simulators internally, like, what is the timeline like for you all in, like, how much of a guess a resource I don't suck, is it I guess? Or, like, how much you know What? What? What? What do you guys consider when you're kind of doing those that sort of work?

Raina Friedman [Antares]  27:34  
Well, I think our approach is always to try to run interim everything. So interim tables during field even setting up the turf and the filters and things like that, well in advance of field clothes. Because once the structure is set into place, it's not it doesn't take a long time to to finalize it, putting in the final data, re running it and doing a check, but then the initial setups for for either of those elements is usually a few days. So it's going to take, you know, two to three days, depending on the size and the magnitude of what's needed, to even get the setup done. And then we need at least a day to kind of double check everything and review it. So we review it very thoroughly at the interim phase. So once we get that piece out of the way, we're really just loading into it the final data and, you know, checking that all the bases line up, you know, but the overall structure we know to be sound. So that's usually same day. I mean, we're doing it within a few hours. For the tables and for the final simulators, it's usually one to two days, depending on if we had to make any changes. Or, you know, we're running those within 24 hours.

Jason Anderson  28:59  
And then related point like, how often are you kind of running kind of tabs for, you know, people,

Bob Hettel [Antares]  29:09  
well, in in the hawk room, if, if we look back 12 months, it would have been, you know, maybe 5% of projects, something like that, lately, say the last quarter or so, it's probably like 50% of projects. So it's kind of shifted a lot over last year in particular. But as we got later in the year, it picked up steam where we see it to be like sort of a standard. Always we do it. It's usually a rush project, right? Yeah, program over the weekend, field for three days, deliver data the next day kind of thing. So that's almost always going to include tabs. But I think part of it too is you guys got so busy last year, and Joe's ability. To handle the volume also became an issue. We saw more and more people asking us to run tables. Yeah, yeah, yeah. So whether that trend continues or not, I don't know, but, you know, I would suspect that we'll see more tables than we have in the past. I think in part, because people just realize we can do them.

Jason Anderson  30:16  
Yeah, no, me, and me and pair are definitely singing your praises.

Bob Hettel [Antares]  30:22  
So I mean, and when rated, talks to about the timeline of like, two or three days to set up the tables. That's not necessarily two to three man hour days, but it's just, you know, you're working on 10 things at once, right? So the tools out there that were most common now, like wind cross is probably the most common tab package that most people use, or a lot of people use, that actually is, again, you can do a lot of things programmatically via script, but you can also do drag and drop, which, if you're just doing, like, I got to include every question. Just want a basic thing. You drag them in. It's ready to go, and it's done. It's really from there you start customizing. I want, you know, I want a summary table of, you know, these 10 attributes of just top two box, right? They're the things you build out very similar to, like, what you're talking about here, that those are special runs that you kind of have to clarify, right? But, yeah, I mean, it's, it's, I think back to the old days, because I'm old. You know, the old days, a tab guy would spend three days, four days, writing code, testing code, to create tables based on things like quantum from way back in the old days, the tab packages that are out there now have come a long way, right? And that has simplified things a lot. But even so, I mean, let's say it takes a tab programmer, let's just say they spend eight hours creating tables. You know, the ability to do that in half an hour is a significant savings, and then, no good.

Jason Anderson  32:07  
Yeah. Just one other question I wanted to get to was doing this project I kind of also thought through, like hmm, maybe some of the strategies that I use for this could kind of help with some other aspects of fielding. So some things I'm thinking about are, you know, Link testing or Q seeing data based on stuff. Like, there's one thing that QC based off of, you know, your speeding or straight lining, but then there's another QC to make sure that the people who you know should get a question are getting that question right. And I think that's takes needing you know that survey right. It takes needing to be able to read that survey and compare that to the data that is there. And then maybe there's you know something there that if you kind of have AI, able to link test the survey for you. You're able to, kind of catch things earlier, catch more of those things. Reduce the, you know, potential risk in the QC process. But even have aI handle QC could also be helpful. So I guess my question would be, you know, one does that seem like, you know, when you're thinking of cross tabbing, Link testing, Q seeing, you know, are those in the top three of some of the things that are time sucks for, you know, market research companies. Or are those, you know, or even for you or are those sort of on another, you know, lower level, and there's other things that sort of rise to the top.

Bob Hettel [Antares]  33:33  
I mean, operationally, Link testing is not inconsequential, right? But in part of that is there are so many parties involved in link testing. So we test, you test, maybe your client test, and all of us are testing for similar things, right? So there's the logic testing, and then there's obviously, does the questionnaire match the questionnaire right on screen versus paper? And then there's the as what I'm seeing on the screen making sense, both in terms of how it's worded, now that it matches. But should it be worded that way, right? Or am I missing answer choices that I didn't realize until I'm actually testing right? So those are the things that I think are, you know, again, we can run dummy data and have things automate to quote, test things. And there are commercial tools out there that will test your questionnaire for you in terms of it'll try to learn your logic and all the other things which also can be used in a negative way. Right? Those same tools can be used to create delete real data, so to speak, right? Right? But, yeah, I mean, that's certainly an area of focus. The QC checks are time consuming, but not probably in the way that you think, like things like speeding and straight lining. You know, those can be flagged and dealt with either in real time in the actual survey, or quickly at the end, because you have a marker that shows you those the things that really take time are reading that open end and saying, number one, does the open end answer? The answer is the open end. Is there something suspicious about the open end itself, in terms of the words used, the punctuation used the format, like, there's a proper case, and all of those things, right? All come into some of that we've tried various tools to validate. Like, here's the question, here's the answer, is this correct? From an AI perspective, we're ending up with more false positives than not, right? So it's throwing out good stuff. It's keeping bad stuff. We found it so inconsistent that we're still having to do it by hand. So we're just not using it for those for that particular purpose of, did the person answer the open end correctly? Right? But I mean, those are time consuming areas of like QC checking. And we, honestly, we work with a lot of clients who are doing other checks on their end as well. And I find some of those can be, I mean, they can take a week to do a QC check on the file, so I know they're spending a lot of time on it. Yeah, they're not necessarily finding things that we're not finding, but what they're doing is flagging things that they're looking at that are logical within the survey, that are not based on a logical it's not like they skipped a question, or they sped or they straight line. They're like, We don't like people who said 15% to this answer,

Raina Friedman [Antares]  36:54  
right? And

Bob Hettel [Antares]  36:57  
you it's just an arbitrary number that they're feeling that if you said more than that, it's not valid. Yeah, and I don't know how, like, an auto, automated tool would solve for that issue, yep, because it wouldn't know what value you're looking for, right? Which we've also said, it becomes what the values are. We can flag those or remove those,

Jason Anderson  37:19  
or whatever. Yeah, makes sense.

Bob Hettel [Antares]  37:22  
So, but yeah. I mean, those are the areas. I mean, there are some tools out there doing those things, but not all.

Raina Friedman [Antares]  37:28  
Yeah, I do think from the program testing perspective, as Bob was kind of talking about, you know, there's so many different elements to that one of them is absolutely testing all the logic. So I do feel as though having support from a technical perspective, like an AI intervention there to be checking to make sure that all the data is in place, that nothing was skipped that shouldn't have been that type of thing could potentially cut down on testing every path manually, but I do feel Like you're still going to have to spend a fair amount of time. Should I have been asked this question? Wait a minute, five questions ago, I said I didn't do that, so I shouldn't be asked this question later on about what I was doing. So I think more often than not, the majority of changes we see to survey questionnaires are more related to changing the questions, adding show logic, changing show logic, whereby, if the AI is just saying, Hey, did the people who were supposed to get this get this Based on what I wrote, I think we'd still miss a lot in terms of actually, what we wrote is probably not wanted. Do you know what I'm saying?

Jason Anderson  39:04  
Yeah, yeah, totally. And, you know, part of the thinking definitely was, you know, you have, maybe the first pass is just straight paths, right? Straight logic path. Just make sure there is no data that's not supposed to be in the right place. And I think that, you know, in my head, that's a piece, at least on my end, that is kind of annoying to do, and feel like it's something that definitely some sort of automated process can work through. But then I do definitely agree there are some moments, or probably, as you said, the majority of the time, we're really trying to look through, does this question even look good, right? Is this the right way to ask a question? You know, is this fatiguing? And there's no way that AI is going to be able to tell you if something's fatiguing or not for a human So, yeah, there's definitely aspects of the link testing. Process that, you know, a human being might still have to do. Maybe there's a pre process that could at least assure the human you don't have to worry about logic, right? Just go through and focus on these higher level things to make sure that the survey is flows, you know, even better than maybe it would if you had to, kind of, you know, waste your cognitive load on, you know, logic, things that could be automated,

Raina Friedman [Antares]  40:16  
yeah, yeah. And, you know, like I was saying, I completely agree. I do think that that would help to minimize or cut down on the time spent for, you know, again, testing every path right, because sometimes it's almost impossible to do right based on how many paths there are and and whatnot, right?

Jason Anderson  40:37  
Well, thank you so much for kind of talking to me today. Learned definitely a lot. Yeah, as I said, it's just, you know, being a hawk partner is my first job, so I don't really know how other things are run and what's normal, what's not normal? I know Hawk partners definitely isn't normal. That's what I do know. So you know, I learning what is normal is definitely good for my brain.

Bob Hettel [Antares]  41:04  
Yeah, one thing I'll tell you is, there is no normal. Okay, everybody is look at everybody is probably 75% the same, but it's that 25% that throws things off.

Jason Anderson  41:19  
No, that's probably, yeah, that sounds right.

Bob Hettel [Antares]  41:24  
But this is actually very intriguing. It's I've not seen anybody kind of going down this road, like I said either commercially speaking, right? Like, I haven't seen any of the normal players out there working on this technology or approach, and I haven't really seen it elsewhere as well. So it's definitely

Jason Anderson  41:48  
interesting, awesome, and I'll definitely keep you all posted. I'm going to look into the stack data. That'll probably be my next update whenever I get there. So yeah, be on the lookout for that. And as I said, Thank you so much for all the feedback and the thoughts. Really appreciate it,

Raina Friedman [Antares]  42:06  
of course, for sure, yeah, and if you have any questions about the stack data or how we're generally setting that up on our end. Happy to have those conversations as well. All right,

Jason Anderson  42:19  
we'll do I will definitely take you up on that.

Jason Anderson  42:23  
Okay, sounds good. Thanks, Jason. All right. Thank you. Have a great day. Bye. Bye. You.

